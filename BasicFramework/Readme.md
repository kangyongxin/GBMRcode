
基本框架的构造，数据流的验证。每设计一个带参数的环节都要想好用什么来训练它。

# 基本功能划分

函数入口 run.py
    
    +  完成整个智能体运行的流程  
    +  超参数的引入
        + 需要后期进行调节的超参数
    +  环境的定义
        + pycolab key_to_door
        + ** 我们要找到一个可以运行的环境，Atari 游戏能做吗？如果做的话需要什么样的包装？**
        + ** 执行状况的可视化 **
    +  环境的封装
        + **暂时没有做batch封装，也就是目前每次只运行一个环境，如果每次运行多个环境那么训练的过程中就要相应地增加维度**
    +  智能体的构造
        + 初始化GBMRagent类
            + 这里的参数有动作空间，状态空间（这两个应该由环境构造环节给出，不应该由我们手动写入），记忆长度（如果想限定记忆长度，应该在什么地方进行？我们应该有一个遗忘模块，在我们进行写内存之前，决定我们要将什么样的内存忘记，但是这个过程是要用阈值的方式完成还是要用以个网络进行训练，如果用网络训练，我们要如何衡量遗忘的过程是否准确呢），记忆维度（记忆维度等同于编码器的编码长度）
        + **参数有点儿混乱，需要重新整理**
        + GBMRagent.py 中的Agent类，主要负责连接各个模块，并提供接口函数给run

    +  训练网络的初始化
        + agent.vae_initial()
        + 我们可以尝试把所有网络同时初始化

    +  与环境的交互
        + 初始环境
        + 根据当前状态进行正向推断，得到决策 infer
            + create_read_info(state,epshistory) 这里当前还只是根据state 产生read info, 没有将轨迹融合进来，理想状况应该是由一条轨迹产生一组read_info
            + read from memory 这个目前也是直接索引得到的， Gmemory.read_edges_of_node(read_node)，**这显然不对**
            + action 由 controller 的 policy net 给出，当前的做法，是把对几个返回的动作随机选择。
        
    +  结果的存储
        + 记录当前轨迹 每条轨迹存储一次
        + memory update() 先删除memory_eraser, **这里要考虑好删除什么样的记忆**，删除的记忆要与当前的观测有关；再写入，写入的位置并不一定是删除的位置，删除的意思是我们要控制总体的量，memory writer

    +  重构机制的调用
        + 先进行抽象 memory abstract ， 在controller 中完成， build abstract graph: self_vec neigh_vecs 得到output ， 然后进行pooling， 得到最具代表性的状态，构成抽象图。**这里都是可以有参数的，只是现在不知道用什么进行训练**

        + 然后根据抽象结果进行重构 memory reconstruction

    +  整体网络的训练
        + vae 的训练
        + 读写函数的训练
        + 抽象函数的训练

环境文件夹 env

    + 其中每个文件构造一个环境，并且配有单独测试的文件
    + 环境的封装

智能体构造 GBMRagent.py

    + 关于智能体的四个部分的衔接和调用

控制器构造 Controller.py

    + 一个抽象图，也就是聚类的结果的转化和处理
    + 编码器解码器 EncoderDecoder.py
    + 策略网络 controller.policynet()
    + 本回合历史的记录 目前直接存在agent中
    + 接口

读写器构造 MemReadWrite.py

    + 读索引 memreader
    + 写索引 这里只负责写与环境交互的结果，因为这个结果需要编码
    + 遗忘机制
    + 相似度

存储器构造 Memory.py

    + 图的构造
    + 图的写入
    + 图的读出
    + 图的删除
    + 边权的更新 对于一条轨迹我们是否有必要从末尾开始更新，以保证连续性

重构机制 MemReconstruction.py

    + 图神经网络的实现
    + 构造基本的聚类loss
    + 针对关键节点之间的路径进行重新训练

其它函数 Util.py

    + 其它用到的函数


接下来要思考的是如何设计实验？
